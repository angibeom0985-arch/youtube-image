import { GoogleGenAI, Type, Modality, GenerateContentResponse } from "@google/genai";
import { RawCharacterData, Character, AspectRatio, ImageStyle, PhotoComposition } from '../types';

// í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜, ëŸ°íƒ€ì„ì—ì„œ ë™ì ìœ¼ë¡œ ì„¤ì •
const getGoogleAI = (apiKey?: string) => {
    const key = apiKey || process.env.API_KEY || process.env.GEMINI_API_KEY;
    if (!key) {
        throw new Error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Google AI Studioì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ ì…ë ¥í•´ì£¼ì„¸ìš”.");
    }
    return new GoogleGenAI({ apiKey: key });
};

// Utility to convert file to base64
const fileToBase64 = (file: File): Promise<string> => {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.readAsDataURL(file);
        reader.onload = () => resolve((reader.result as string).split(',')[1]);
        reader.onerror = error => reject(error);
    });
};

const extractJson = (text: string): any => {
    const match = text.match(/```json\n([\s\S]*?)\n```/);
    if (match && match[1]) {
        try {
            return JSON.parse(match[1]);
        } catch (e) {
            console.error("Failed to parse JSON from markdown", e);
            throw new Error("Invalid JSON format returned from API.");
        }
    }
    // Fallback for raw JSON string
    try {
        return JSON.parse(text);
    } catch (e) {
         console.error("Failed to parse raw JSON string", e);
         throw new Error("Could not find or parse JSON in the response.");
    }
};

// ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
const getStylePrompt = (style: string): string => {
    const styleMap: Record<string, string> = {
        'ê°ì„± ë©œë¡œ': 'romantic and emotional atmosphere, soft warm lighting, dreamy mood',
        'ì„œë¶€ê·¹': 'western film style, rugged cowboy aesthetic, dusty desert atmosphere',
        'ê³µí¬ ìŠ¤ë¦´ëŸ¬': 'dark and mysterious atmosphere, dramatic shadows, suspenseful mood',
        '1980ë…„ëŒ€': '1980s retro style, vintage 80s fashion, neon colors, retro aesthetic',
        '2000ë…„ëŒ€': '2000s Y2K style, early 2000s fashion, urban contemporary look',
        'ì‚¬ì´ë²„í‘í¬': 'cyberpunk futuristic style, neon lights, high-tech urban environment',
        'íŒíƒ€ì§€': 'fantasy medieval style, magical atmosphere, enchanted setting',
        'ë¯¸ë‹ˆë©€': 'minimalist clean style, simple composition, neutral tones',
        'ë¹ˆí‹°ì§€': 'vintage classic style, aged film aesthetic, nostalgic mood',
        'ëª¨ë˜': 'modern contemporary style, clean urban aesthetic, sophisticated look'
    };
    
    return styleMap[style] || style;
};

// êµ¬ë„ í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
const getCompositionPrompt = (composition: PhotoComposition): string => {
    const compositionMap: Record<PhotoComposition, string> = {
        'ì •ë©´': 'Front view, facing camera directly',
        'ì¸¡ë©´': 'Side view, profile shot',
        'ë°˜ì¸¡ë©´': 'Three-quarter view, slightly turned',
        'ìœ„ì—ì„œ': 'High angle shot, view from above',
        'ì•„ë˜ì—ì„œ': 'Low angle shot, view from below',
        'ì „ì‹ ': 'Full body shot, entire person visible',
        'ìƒë°˜ì‹ ': 'Upper body shot, waist up portrait',
        'í´ë¡œì¦ˆì—…': 'Close-up headshot, detailed facial features'
    };
    
    return compositionMap[composition];
};

export const generateCharacters = async (
    script: string, 
    apiKey?: string, 
    imageStyle: 'realistic' | 'animation' = 'realistic',
    aspectRatio: AspectRatio = '16:9',
    personaStyle?: ImageStyle,
    customStyle?: string,
    photoComposition?: PhotoComposition,
    customPrompt?: string
): Promise<Character[]> => {
    try {
        console.log("ğŸš€ Starting character generation process...");
        console.log("ğŸ“ Script:", script.substring(0, 100) + "...");
        console.log("ğŸ”‘ API Key provided:", !!apiKey);
        console.log("ğŸ¨ Image Style:", imageStyle);
        console.log("ğŸ“ Aspect Ratio:", aspectRatio);
        
        const ai = getGoogleAI(apiKey);
        console.log("âœ… GoogleAI instance created successfully");
        
        console.log("Step 1: Analyzing script for characters...");
        const analysisPrompt = `ë‹¤ìŒ í•œêµ­ì–´ ëŒ€ë³¸ì„ ë§¤ìš° ì„¸ë°€í•˜ê²Œ ë¶„ì„í•˜ì—¬ ì£¼ìš” ë“±ì¥ì¸ë¬¼ì„ ì‹ë³„í•˜ì„¸ìš”. 
    
ëŒ€ë³¸ì˜ ë§¥ë½ê³¼ ìŠ¤í† ë¦¬ì— ì™„ë²½í•˜ê²Œ ë§ëŠ” ìºë¦­í„°ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤:
1. ëŒ€ë³¸ì—ì„œ ì–¸ê¸‰ëœ ë“±ì¥ì¸ë¬¼ì˜ ì—­í• , ë‚˜ì´, ì„±ê²©ì„ ì •í™•íˆ íŒŒì•…
2. ëŒ€ë³¸ì˜ ì‹œëŒ€ì  ë°°ê²½, ì¥ë¥´, ë¶„ìœ„ê¸°ì— ë§ëŠ” ìºë¦­í„° ì„¤ì •
3. ê° ë“±ì¥ì¸ë¬¼ì˜ ì™¸ëª¨ëŠ” ê·¸ë“¤ì˜ ì—­í• ê³¼ ì„±ê²©ì„ ë°˜ì˜í•´ì•¼ í•¨
4. í•œêµ­ì¸ì˜ íŠ¹ì§•ì„ ê°€ì§„ ì¸ë¬¼ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”

ê° ë“±ì¥ì¸ë¬¼ì— ëŒ€í•´:
- name: ëŒ€ë³¸ì— ë‚˜ì˜¨ ì´ë¦„ ë˜ëŠ” ì—­í• ëª… (ì˜ˆ: "ê¹€ì˜ìˆ˜", "ì˜ì‚¬", "í•™ìƒ" ë“±)
- description: ëŒ€ë³¸ì˜ ë§¥ë½ì— ë§ëŠ” êµ¬ì²´ì ì¸ ì™¸ëª¨ ë¬˜ì‚¬ (ë‚˜ì´ëŒ€, ë³µì¥, í‘œì •, ì²´í˜•, í—¤ì–´ìŠ¤íƒ€ì¼, í•œêµ­ì¸ íŠ¹ì§• í¬í•¨)

ê²°ê³¼ë¥¼ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”: \`[{name: string, description: string}]\`

ëŒ€ë³¸: \n\n${script}`;

    console.log("ğŸ”„ Calling Gemini API for character analysis...");
    const analysisResponse = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: analysisPrompt,
        config: {
            responseMimeType: "application/json",
            responseSchema: {
                type: Type.ARRAY,
                items: {
                    type: Type.OBJECT,
                    properties: {
                        name: { type: Type.STRING },
                        description: { type: Type.STRING }
                    },
                    required: ["name", "description"]
                }
            }
        }
    });

    console.log("âœ… Character analysis API call completed");
    console.log("ğŸ“„ Raw response:", analysisResponse.text);
    
    const characterData: RawCharacterData[] = JSON.parse(analysisResponse.text);
    console.log("ğŸ“‹ Parsed character data:", characterData);

    console.log(`Step 2: Generating images for ${characterData.length} characters sequentially...`);
    
    // ìˆœì°¨ì ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±í•˜ì—¬ rate limit ë°©ì§€
    const successfulCharacters: Character[] = [];
    const failedErrors: string[] = [];
    
    for (let i = 0; i < characterData.length; i++) {
        const char = characterData[i];
        console.log(`Processing character ${i + 1}/${characterData.length}: ${char.name}`);
        
        try {
            // ê° ìš”ì²­ ì‚¬ì´ì— 2ì´ˆ ì§€ì—°
            if (i > 0) {
                console.log('Waiting 2 seconds before next request...');
                await new Promise(resolve => setTimeout(resolve, 2000));
            }
            
            // í”„ë¡¬í”„íŠ¸ ìƒì„±
            let contextualPrompt: string;
            
            if (customPrompt && customPrompt.trim()) {
                // ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì‚¬ìš©
                contextualPrompt = customPrompt;
            } else {
                // ìŠ¤íƒ€ì¼ê³¼ êµ¬ë„ ì •ë³´ ìƒì„±
                const styleText = personaStyle === 'custom' && customStyle ? customStyle : personaStyle || 'ëª¨ë˜';
                const compositionText = getCompositionPrompt(photoComposition || 'ì •ë©´');
                const stylePrompt = getStylePrompt(styleText);
                
                if (imageStyle === 'animation') {
                    contextualPrompt = `${compositionText} anime/animation style character portrait of ${char.name}. ${char.description}. 
                    ${stylePrompt} Korean anime character design, clean anime art style, colorful and vibrant, 
                    detailed anime facial features, appropriate for the character's role and personality described in the script. 
                    Studio-quality anime illustration, professional anime character design. Only one person in the image, no subtitles, no speech bubbles, no text, no dialogue.`;
                } else {
                    contextualPrompt = `${compositionText} professional portrait photograph of ${char.name}. ${char.description}. 
                    ${stylePrompt} High quality Korean person headshot, natural lighting, neutral background, photorealistic style, 
                    detailed facial features, appropriate for the character's role and personality described in the script. 
                    Focus on realistic Korean facial features, professional photography quality. Only one person in the image, no subtitles, no speech bubbles, no text, no dialogue.`;
                }
            }
            
            const imageResponse = await ai.models.generateImages({
                model: 'imagen-4.0-generate-001',
                prompt: contextualPrompt,
                config: {
                    numberOfImages: 1,
                    outputMimeType: 'image/jpeg',
                    aspectRatio: aspectRatio,
                },
            });

            const imageBytes = imageResponse.generatedImages?.[0]?.image?.imageBytes;

            if (!imageBytes) {
                console.warn(`Image generation failed for character: ${char.name}, using fallback`);
                // ì‹¤íŒ¨í•œ ê²½ìš° ë” ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
                const fallbackPrompt = imageStyle === 'animation' 
                    ? `Single person simple anime character of a Korean person representing ${char.name}. Clean anime style, neutral background, no subtitles, no speech bubbles, no text.`
                    : `Single person professional headshot of a Korean person representing ${char.name}. Clean background, neutral expression, photorealistic, no subtitles, no speech bubbles, no text.`;
                    
                await new Promise(resolve => setTimeout(resolve, 1000)); // 1ì´ˆ ì¶”ê°€ ì§€ì—°
                
                const fallbackResponse = await ai.models.generateImages({
                    model: 'imagen-4.0-generate-001',
                    prompt: fallbackPrompt,
                    config: {
                        numberOfImages: 1,
                        outputMimeType: 'image/jpeg',
                        aspectRatio: aspectRatio,
                    },
                });
                
                const fallbackBytes = fallbackResponse.generatedImages?.[0]?.image?.imageBytes;
                if (!fallbackBytes) {
                    throw new Error(`Both image generation and fallback failed for character: ${char.name}`);
                }
                
                successfulCharacters.push({
                    id: self.crypto.randomUUID(),
                    name: char.name,
                    description: char.description,
                    image: fallbackBytes,
                });
            } else {
                successfulCharacters.push({
                    id: self.crypto.randomUUID(),
                    name: char.name,
                    description: char.description,
                    image: imageBytes,
                });
            }
            
            console.log(`Successfully generated image for ${char.name}`);
        } catch (error) {
            console.error(`Error generating image for ${char.name}:`, error);
            failedErrors.push(`${char.name}: ${error instanceof Error ? error.message : 'Unknown error'}`);
        }
    }
    
    if (failedErrors.length > 0) {
        console.warn('Some characters failed to generate:', failedErrors);
        if (successfulCharacters.length === 0) {
            throw new Error('All character generation failed. Please try with different content or check your internet connection.');
        }
    }
    
    console.log("âœ… Character generation completed successfully!");
    console.log(`ğŸ“Š Generated ${successfulCharacters.length} characters`);
    return successfulCharacters;
    
    } catch (error) {
        console.error("âŒ Character generation failed:", error);
        
        // ë” êµ¬ì²´ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ
        if (error instanceof Error) {
            if (error.message.includes('API_KEY_INVALID') || error.message.includes('Invalid API key')) {
                throw new Error('ì˜¬ë°”ë¥´ì§€ ì•Šì€ API í‚¤ì…ë‹ˆë‹¤. Google AI Studioì—ì„œ ìƒˆë¡œìš´ API í‚¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.');
            } else if (error.message.includes('PERMISSION_DENIED') || error.message.includes('permission')) {
                throw new Error('API í‚¤ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. Imagen APIê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.');
            } else if (error.message.includes('QUOTA_EXCEEDED') || error.message.includes('quota')) {
                throw new Error('API ì‚¬ìš©ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ìš”ê¸ˆì œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.');
            } else if (error.message.includes('RATE_LIMIT_EXCEEDED') || error.message.includes('rate limit')) {
                throw new Error('ë„ˆë¬´ ë§ì€ ìš”ì²­ì„ ë³´ëƒˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
            }
        }
        
        throw error;
    }
};

export const regenerateCharacterImage = async (
    description: string, 
    name: string, 
    apiKey?: string, 
    imageStyle: 'realistic' | 'animation' = 'realistic',
    aspectRatio: AspectRatio = '16:9'
): Promise<string> => {
    const ai = getGoogleAI(apiKey);
    console.log(`Regenerating image for ${name}...`);
    
    try {
        // ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
        let imagePrompt: string;
        
        if (imageStyle === 'animation') {
            imagePrompt = `Single person high quality anime/animation style character illustration of ${name}. ${description}. 
            Korean anime character design, clean anime art style, colorful and vibrant, 
            detailed anime facial features. Studio-quality anime illustration. Only one person in the image, no subtitles, no speech bubbles, no text, no dialogue.`;
        } else {
            imagePrompt = `Single person professional portrait photograph of ${name}. ${description}. 
            High quality Korean person headshot, natural lighting, neutral background, photorealistic style, 
            detailed facial features. Professional photography quality. Only one person in the image, no subtitles, no speech bubbles, no text, no dialogue.`;
        }

        const imageResponse = await ai.models.generateImages({
            model: 'imagen-4.0-generate-001',
            prompt: imagePrompt,
            config: {
                numberOfImages: 1,
                outputMimeType: 'image/jpeg',
                aspectRatio: aspectRatio,
            },
        });

        const imageBytes = imageResponse.generatedImages?.[0]?.image?.imageBytes;
        if (!imageBytes) {
            // ì‹¤íŒ¨í•œ ê²½ìš° ë” ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
            console.warn(`Initial regeneration failed for ${name}, trying with simpler prompt...`);
            
            const fallbackResponse = await ai.models.generateImages({
                model: 'imagen-4.0-generate-001',
                prompt: `A single person simple professional portrait of a friendly person. Clean style, neutral background, no subtitles, no speech bubbles, no text.`,
                config: {
                    numberOfImages: 1,
                    outputMimeType: 'image/jpeg',
                    aspectRatio: aspectRatio,
                },
            });
            
            const fallbackBytes = fallbackResponse.generatedImages?.[0]?.image?.imageBytes;
            if (!fallbackBytes) {
                throw new Error(`Image regeneration failed for character: ${name}. Please try with a different description.`);
            }
            
            return fallbackBytes;
        }

        return imageBytes;
    } catch (error) {
        console.error(`Error regenerating image for ${name}:`, error);
        throw new Error(`Image regeneration failed for character: ${name}. This might be due to content policy restrictions. Please try with a different character description.`);
    }
};


export const generateStoryboard = async (
    script: string, 
    characters: Character[], 
    imageCount: number, 
    apiKey?: string, 
    imageStyle: 'realistic' | 'animation' = 'realistic',
    subtitleEnabled: boolean = true,
    referenceImage?: string | null,
    aspectRatio: AspectRatio = '16:9'
): Promise<{id: string, image: string, sceneDescription: string}[]> => {
    const ai = getGoogleAI(apiKey);
    console.log("Step 1: Generating scene descriptions...");
    const scenesPrompt = `ë‹¤ìŒ í•œêµ­ì–´ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì„¸ìš”. ${imageCount}ê°œì˜ ì£¼ìš” ì‹œê°ì  ì¥ë©´ìœ¼ë¡œ ë‚˜ëˆ„ì„¸ìš”. ê° ì¥ë©´ì— ëŒ€í•´ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì§§ê³  ì„¤ëª…ì ì¸ ìº¡ì…˜ì„ í•œêµ­ì–´ë¡œ ì œê³µí•˜ì„¸ìš”. ê²°ê³¼ë¥¼ ë¬¸ìì—´ì˜ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”: \`["ì¥ë©´ 1 ì„¤ëª…", "ì¥ë©´ 2 ì„¤ëª…", ...]\`. ëŒ€ë³¸: \n\n${script}`;
    
    const scenesResponse = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: scenesPrompt,
        config: {
            responseMimeType: "application/json",
            responseSchema: {
                type: Type.ARRAY,
                items: { type: Type.STRING }
            }
        }
    });

    const sceneDescriptions: string[] = JSON.parse(scenesResponse.text);

    console.log(`Step 2: Generating ${sceneDescriptions.length} storyboard images sequentially...`);

    const storyboardResults: any[] = [];
    
    for (let i = 0; i < sceneDescriptions.length; i++) {
        const scene = sceneDescriptions[i];
        console.log(`Processing scene ${i + 1}/${sceneDescriptions.length}: ${scene.substring(0, 50)}...`);
        
        try {
            // ê° ìš”ì²­ ì‚¬ì´ì— 3ì´ˆ ì§€ì—° (ì˜ìƒ ì†ŒìŠ¤ëŠ” ë” ë³µì¡í•˜ë¯€ë¡œ)
            if (i > 0) {
                console.log('Waiting 3 seconds before next scene generation...');
                await new Promise(resolve => setTimeout(resolve, 3000));
            }
            
            const parts: any[] = [];
            
            // ì°¸ì¡° ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
            if (referenceImage) {
                parts.push({
                    inlineData: {
                        data: referenceImage,
                        mimeType: 'image/jpeg'
                    }
                });
                parts.push({ text: 'Style reference image - please maintain consistency with this visual style' });
            }
            
            characters.forEach(char => {
                parts.push({
                    inlineData: {
                        data: char.image,
                        mimeType: 'image/jpeg' 
                    }
                });
                parts.push({ text: `Reference image for character: ${char.name}` });
            });

            // ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸
            let imageGenPrompt: string;
            const subtitleText = subtitleEnabled ? 'í•œêµ­ì–´ ìë§‰ì„ í¬í•¨í•˜ì—¬' : 'ìë§‰ ì—†ì´';
            const referenceText = referenceImage ? ' ì œê³µëœ ìŠ¤íƒ€ì¼ ì°¸ì¡° ì´ë¯¸ì§€ì˜ ì‹œê°ì  ì¼ê´€ì„±ì„ ìœ ì§€í•˜ë©´ì„œ' : '';
            
            if (imageStyle === 'animation') {
                imageGenPrompt = `ì œê³µëœ ì°¸ì¡° ìºë¦­í„° ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬${referenceText} ì´ ì¥ë©´ì— ëŒ€í•œ ì• ë‹ˆë©”ì´ì…˜ ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ë¥¼ ${subtitleText} ë§Œë“œì„¸ìš”: "${scene}". 
                ì¥ë©´ì— ë‚˜ì˜¤ëŠ” ìºë¦­í„°ì˜ ì–¼êµ´ê³¼ ì™¸ëª¨ê°€ ì°¸ì¡° ì´ë¯¸ì§€ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. 
                ì• ë‹ˆë©”ì´ì…˜/ë§Œí™” ìŠ¤íƒ€ì¼ë¡œ ê·¸ë ¤ì£¼ì„¸ìš”. ë°ê³  ì»¬ëŸ¬í’€í•œ ì• ë‹ˆë©”ì´ì…˜ ì•„íŠ¸ ìŠ¤íƒ€ì¼, ${aspectRatio} ë¹„ìœ¨ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³ , 
                ì£¼ìš” ì¸ë¬¼ì´ë‚˜ ì‚¬ë¬¼ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ êµ¬ë„ë¥¼ ì¡ì•„ì£¼ì„¸ìš”.${subtitleEnabled ? ' í™”ë©´ í•˜ë‹¨ì— í•œêµ­ì–´ ìë§‰ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜í•´ì£¼ì„¸ìš”.' : ''}`;
            } else {
                imageGenPrompt = `ì œê³µëœ ì°¸ì¡° ìºë¦­í„° ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬${referenceText} ì´ ì¥ë©´ì— ëŒ€í•œ ì‚¬ì‹¤ì ì¸ ì´ë¯¸ì§€ë¥¼ ${subtitleText} ë§Œë“œì„¸ìš”: "${scene}". 
                ì¥ë©´ì— ë‚˜ì˜¤ëŠ” ìºë¦­í„°ì˜ ì–¼êµ´ê³¼ ì™¸ëª¨ê°€ ì°¸ì¡° ì´ë¯¸ì§€ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. 
                ì‹¤ì‚¬ ì˜í™” ìŠ¤íƒ€ì¼, ì‹œë„¤ë§ˆí‹± ${aspectRatio} ë¹„ìœ¨ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³ , ì£¼ìš” ì¸ë¬¼ì´ë‚˜ ì‚¬ë¬¼ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ êµ¬ë„ë¥¼ ì¡ì•„ì£¼ì„¸ìš”.${subtitleEnabled ? ' í™”ë©´ í•˜ë‹¨ì— í•œêµ­ì–´ ìë§‰ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜í•´ì£¼ì„¸ìš”.' : ''}`;
            }
            parts.push({ text: imageGenPrompt });

            const imageResponse = await ai.models.generateContent({
                model: 'gemini-2.5-flash-image-preview',
                contents: { parts },
                // FIX: Removed unsupported `temperature` config for the image editing model.
                config: {
                    responseModalities: [Modality.IMAGE, Modality.TEXT],
                }
            });

            const imagePart = imageResponse.candidates?.[0]?.content?.parts?.find(part => part.inlineData);
            if (!imagePart?.inlineData?.data) {
                console.warn(`Image generation might have failed for scene: ${scene}`);
                storyboardResults.push({ id: self.crypto.randomUUID(), image: '', sceneDescription: scene });
            } else {
                storyboardResults.push({
                    id: self.crypto.randomUUID(),
                    image: imagePart.inlineData.data,
                    sceneDescription: scene,
                });
                console.log(`Successfully generated image for scene ${i + 1}`);
            }
        } catch (error) {
            console.error(`Error generating scene ${i + 1}:`, error);
            storyboardResults.push({ id: self.crypto.randomUUID(), image: '', sceneDescription: scene });
        }
    }

    return storyboardResults;
};

export const regenerateStoryboardImage = async (
    sceneDescription: string, 
    characters: Character[], 
    apiKey?: string,
    imageStyle: 'realistic' | 'animation' = 'realistic',
    subtitleEnabled: boolean = true,
    referenceImage?: string | null,
    aspectRatio: AspectRatio = '16:9'
): Promise<string> => {
    const ai = getGoogleAI(apiKey);
    console.log(`Regenerating image for scene: ${sceneDescription}`);
    
    const parts: any[] = [];
    
    // ì°¸ì¡° ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
    if (referenceImage) {
        parts.push({
            inlineData: {
                data: referenceImage,
                mimeType: 'image/jpeg'
            }
        });
        parts.push({ text: 'Style reference image - please maintain consistency with this visual style' });
    }
    
    characters.forEach(char => {
        parts.push({ inlineData: { data: char.image, mimeType: 'image/jpeg' } });
        parts.push({ text: `Reference image for character: ${char.name}` });
    });

    // ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸
    let imageGenPrompt: string;
    const subtitleText = subtitleEnabled ? 'í•œêµ­ì–´ ìë§‰ì„ í¬í•¨í•˜ì—¬' : 'ìë§‰ ì—†ì´';
    const referenceText = referenceImage ? ' ì œê³µëœ ìŠ¤íƒ€ì¼ ì°¸ì¡° ì´ë¯¸ì§€ì˜ ì‹œê°ì  ì¼ê´€ì„±ì„ ìœ ì§€í•˜ë©´ì„œ' : '';
    
    if (imageStyle === 'animation') {
        imageGenPrompt = `ì œê³µëœ ì°¸ì¡° ìºë¦­í„° ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬${referenceText} ì´ ì¥ë©´ì— ëŒ€í•œ ì• ë‹ˆë©”ì´ì…˜ ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ë¥¼ ${subtitleText} ë§Œë“œì„¸ìš”: "${sceneDescription}". 
        ì¥ë©´ì— ë‚˜ì˜¤ëŠ” ìºë¦­í„°ì˜ ì–¼êµ´ê³¼ ì™¸ëª¨ê°€ ì°¸ì¡° ì´ë¯¸ì§€ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. 
        ì• ë‹ˆë©”ì´ì…˜/ë§Œí™” ìŠ¤íƒ€ì¼ë¡œ ê·¸ë ¤ì£¼ì„¸ìš”. ë°ê³  ì»¬ëŸ¬í’€í•œ ì• ë‹ˆë©”ì´ì…˜ ì•„íŠ¸ ìŠ¤íƒ€ì¼, ${aspectRatio} ë¹„ìœ¨ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³ , 
        ì£¼ìš” ì¸ë¬¼ì´ë‚˜ ì‚¬ë¬¼ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ êµ¬ë„ë¥¼ ì¡ì•„ì£¼ì„¸ìš”.${subtitleEnabled ? ' í™”ë©´ í•˜ë‹¨ì— í•œêµ­ì–´ ìë§‰ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜í•´ì£¼ì„¸ìš”.' : ''}`;
    } else {
        imageGenPrompt = `ì œê³µëœ ì°¸ì¡° ìºë¦­í„° ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬${referenceText} ì´ ì¥ë©´ì— ëŒ€í•œ ìƒì„¸í•œ ì´ë¯¸ì§€ë¥¼ ${subtitleText} ë§Œë“œì„¸ìš”: "${sceneDescription}". 
        ì¥ë©´ì— ë‚˜ì˜¤ëŠ” ìºë¦­í„°ì˜ ì–¼êµ´ê³¼ ì™¸ëª¨ê°€ ì°¸ì¡° ì´ë¯¸ì§€ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. 
        ì‹œë„¤ë§ˆí‹± ${aspectRatio} ë¹„ìœ¨ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³ , ì£¼ìš” ì¸ë¬¼ì´ë‚˜ ì‚¬ë¬¼ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ êµ¬ë„ë¥¼ ì¡ì•„ì£¼ì„¸ìš”.${subtitleEnabled ? ' í™”ë©´ í•˜ë‹¨ì— í•œêµ­ì–´ ìë§‰ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜í•´ì£¼ì„¸ìš”.' : ''}`;
    }
    parts.push({ text: imageGenPrompt });

    const imageResponse = await ai.models.generateContent({
        model: 'gemini-2.5-flash-image-preview',
        contents: { parts },
        // FIX: Removed unsupported `temperature` config for the image editing model.
        config: {
            responseModalities: [Modality.IMAGE, Modality.TEXT],
        }
    });

    const imagePart = imageResponse.candidates?.[0]?.content?.parts?.find(part => part.inlineData);
    if (!imagePart?.inlineData?.data) {
        throw new Error(`Image regeneration failed for scene: ${sceneDescription}`);
    }

    return imagePart.inlineData.data;
};